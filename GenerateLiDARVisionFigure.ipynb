{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+4pW+VQZB6L5DHdYZPmBN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EHaarer/Translating-Pedestrian-Indoor-Images-into-Maps/blob/main/GenerateLiDARVisionFigure.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1xwHIjtjoAJ",
        "outputId": "58e12857-b1b3-472a-eedb-7faedc73d06f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Collecting filterpy\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting timm\n",
            "  Downloading timm-1.0.7-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lap\n",
            "  Downloading lap-0.4.0.tar.gz (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from filterpy) (1.11.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from filterpy) (3.7.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.23.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.3)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy) (2.8.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->filterpy) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.6.2)\n",
            "Building wheels for collected packages: filterpy, lap\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110458 sha256=253bdb34b739957d07bfe9568969a832126cb76eb0ec6909429ca8ba2eb634b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/0c/ea/218f266af4ad626897562199fbbcba521b8497303200186102\n",
            "  Building wheel for lap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lap: filename=lap-0.4.0-cp310-cp310-linux_x86_64.whl size=1628948 sha256=0625cf3cf811fb2298461805d425a1d25bedad021fe0893f7fa2ab9cbb6752b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/42/2e/9dfe19270eea279d79e84767ff0d7b8082c3bf776cad00e83d\n",
            "Successfully built filterpy lap\n",
            "Installing collected packages: lap, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, filterpy, timm\n",
            "Successfully installed filterpy-1.4.5 lap-0.4.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 timm-1.0.7\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.25.2)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "Successfully installed scipy-1.14.0\n",
            "--2024-07-04 17:51:35--  https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4.weights\n",
            "Resolving github.com (github.com)... 140.82.116.4\n",
            "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/75388965/4b8a4e00-b2d7-11eb-900f-678196af5945?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240704%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240704T175135Z&X-Amz-Expires=300&X-Amz-Signature=3793136afceb95224d440952b52c6307d8e933a9f2954aec4ced1ba1bfdc4601&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=75388965&response-content-disposition=attachment%3B%20filename%3Dyolov4.weights&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-07-04 17:51:35--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/75388965/4b8a4e00-b2d7-11eb-900f-678196af5945?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20240704%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240704T175135Z&X-Amz-Expires=300&X-Amz-Signature=3793136afceb95224d440952b52c6307d8e933a9f2954aec4ced1ba1bfdc4601&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=75388965&response-content-disposition=attachment%3B%20filename%3Dyolov4.weights&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 257717640 (246M) [application/octet-stream]\n",
            "Saving to: ‘yolov4.weights’\n",
            "\n",
            "yolov4.weights      100%[===================>] 245.78M   253MB/s    in 1.0s    \n",
            "\n",
            "2024-07-04 17:51:36 (253 MB/s) - ‘yolov4.weights’ saved [257717640/257717640]\n",
            "\n",
            "--2024-07-04 17:51:37--  https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4.cfg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12231 (12K) [text/plain]\n",
            "Saving to: ‘yolov4.cfg’\n",
            "\n",
            "yolov4.cfg          100%[===================>]  11.94K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-07-04 17:51:37 (91.6 MB/s) - ‘yolov4.cfg’ saved [12231/12231]\n",
            "\n",
            "Cloning into 'sort'...\n",
            "remote: Enumerating objects: 208, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 208 (delta 2), reused 2 (delta 1), pack-reused 202\u001b[K\n",
            "Receiving objects: 100% (208/208), 1.21 MiB | 18.43 MiB/s, done.\n",
            "Resolving deltas: 100% (74/74), done.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install torch torchvision filterpy timm lap\n",
        "!pip install --upgrade scipy\n",
        "!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4.weights -O yolov4.weights\n",
        "!wget https://raw.githubusercontent.com/AlexeyAB/darknet/master/cfg/yolov4.cfg -O yolov4.cfg\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "!git clone https://github.com/abewley/sort.git || echo \"SORT directory already exists\"\n",
        "!sed -i 's/matplotlib.use(.TkAgg.)/# matplotlib.use(\"TkAgg\")/' /content/sort/sort.py\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/sort')\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, Resize\n",
        "from PIL import Image as PILImage\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image as DisplayImage, display\n",
        "from scipy import stats\n",
        "import math\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Setup for YOLO\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "yolo_cfg = '/content/yolov4.cfg'\n",
        "yolo_weights = '/content/yolov4.weights'\n",
        "net = cv2.dnn.readNetFromDarknet(yolo_cfg, yolo_weights)\n",
        "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
        "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA_FP16)\n",
        "\n",
        "def apply_nms(boxes, scores, confidence_threshold=0.5, nms_threshold=0.4):\n",
        "    indices = cv2.dnn.NMSBoxes(boxes, scores, confidence_threshold, nms_threshold)\n",
        "    if len(indices) == 0:\n",
        "        return []\n",
        "    indices = indices.flatten()\n",
        "    return [boxes[i] for i in indices]\n",
        "\n",
        "def process_image(image_path, depth_map_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    depth_map = cv2.imread(depth_map_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
        "    Height, Width = image.shape[:2]\n",
        "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    detections = net.forward(net.getUnconnectedOutLayersNames())\n",
        "\n",
        "    boxes = []\n",
        "    confidences = []\n",
        "    for output in detections:\n",
        "        for detection in output:\n",
        "            scores = detection[5:]\n",
        "            classID = np.argmax(scores)\n",
        "            confidence = scores[classID]\n",
        "            if classID == 0 and confidence > 0.5:  # Detecting person\n",
        "                box = detection[0:4] * np.array([Width, Height, Width, Height])\n",
        "                centerX, centerY, width, height = box.astype(\"int\")\n",
        "                x = int(centerX - (width / 2))\n",
        "                y = int(centerY - (height / 2))\n",
        "                boxes.append([x, y, int(width), int(height)])\n",
        "                confidences.append(float(confidence))\n",
        "    boxes = apply_nms(boxes, confidences)\n",
        "\n",
        "    # Draw boxes and lines on the depth map\n",
        "    for box in boxes:\n",
        "        x, y, w, h = box\n",
        "        cv2.rectangle(depth_map, (x, y), (x+w, y+h), (255), 2)  # Draw the box\n",
        "        mid_x = x + w // 2\n",
        "        cv2.line(depth_map, (mid_x, 0), (mid_x, Height), (255), 2)  # Draw the line\n",
        "\n",
        "    # Save the modified depth map to Google Drive\n",
        "    output_path = '/content/drive/My Drive/Adv CV files/3Personprocessed_depth_map.png'\n",
        "    cv2.imwrite(output_path, depth_map)\n",
        "\n",
        "    return image, depth_map, boxes\n",
        "\n",
        "def main():\n",
        "    input_path = '/content/drive/My Drive/Adv CV files/RefinePics/3personTest.jpg'\n",
        "    depth_map_path = '/content/drive/My Drive/Adv CV files/RefinePics/3personTest.png'\n",
        "    image, depth_map, boxes = process_image(input_path, depth_map_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "##BELOW  IS THE ATTEMPT TO GENERATE THE IMAGE WITH COLOR!!! (WIP)\n",
        "# import cv2\n",
        "# import numpy as np\n",
        "# import os\n",
        "\n",
        "# # Setup for YOLO\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# yolo_cfg = '/content/yolov4.cfg'\n",
        "# yolo_weights = '/content/yolov4.weights'\n",
        "# net = cv2.dnn.readNetFromDarknet(yolo_cfg, yolo_weights)\n",
        "# net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
        "# net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA_FP16)\n",
        "\n",
        "# def apply_nms(boxes, scores, confidence_threshold=0.5, nms_threshold=0.4):\n",
        "#     indices = cv2.dnn.NMSBoxes(boxes, scores, confidence_threshold, nms_threshold)\n",
        "#     if len(indices) == 0:\n",
        "#         return []\n",
        "#     indices = indices.flatten()\n",
        "#     return [boxes[i] for i in indices]\n",
        "\n",
        "# def process_image(image_path, depth_map_path):\n",
        "#     image = cv2.imread(image_path)\n",
        "#     depth_map = cv2.imread(depth_map_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
        "#     # Convert grayscale depth map to BGR color for drawing colored shapes\n",
        "#     depth_map_color = cv2.cvtColor(depth_map, cv2.COLOR_GRAY2BGR)\n",
        "#     Height, Width = image.shape[:2]\n",
        "#     blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
        "#     net.setInput(blob)\n",
        "#     detections = net.forward(net.getUnconnectedOutLayersNames())\n",
        "\n",
        "#     boxes = []\n",
        "#     confidences = []\n",
        "#     for output in detections:\n",
        "#         for detection in output:\n",
        "#             scores = detection[5:]\n",
        "#             classID = np.argmax(scores)\n",
        "#             confidence = scores[classID]\n",
        "#             if classID == 0 and confidence > 0.5:  # Detecting person\n",
        "#                 box = detection[0:4] * np.array([Width, Height, Width, Height])\n",
        "#                 centerX, centerY, width, height = box.astype(\"int\")\n",
        "#                 x = int(centerX - (width / 2))\n",
        "#                 y = int(centerY - (height / 2))\n",
        "#                 boxes.append([x, y, int(width), int(height)])\n",
        "#                 confidences.append(float(confidence))\n",
        "#     boxes = apply_nms(boxes, confidences)\n",
        "\n",
        "#     # Draw boxes in blue and vertical lines in red on the depth map\n",
        "#     for box in boxes:\n",
        "#         x, y, w, h = box\n",
        "#         cv2.rectangle(depth_map_color, (x, y), (x+w, y+h), (255, 0, 0), 2)  # Draw the box in blue\n",
        "#         mid_x = x + w // 2\n",
        "#         cv2.line(depth_map_color, (mid_x, 0), (mid_x, Height), (0, 0, 255), 2)  # Draw the line in red\n",
        "\n",
        "#     # Save the modified depth map to Google Drive\n",
        "#     output_path = '/content/drive/My Drive/processed_depth_mapCOLOR.png'\n",
        "#     cv2.imwrite(output_path, depth_map_color)\n",
        "\n",
        "#     return image, depth_map_color, boxes\n",
        "\n",
        "# def main():\n",
        "#     input_path = '/content/drive/My Drive/Adv CV files/RefinePics/3personTest.jpg'\n",
        "#     depth_map_path = '/content/drive/My Drive/Adv CV files/RefinePics/3personTest.png'\n",
        "#     image, depth_map_color, boxes = process_image(input_path, depth_map_path)\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()"
      ],
      "metadata": {
        "id": "K1TznHZKmRV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Given data points\n",
        "points = np.array([\n",
        "    (171, 12), (168, 18), (161, 18), (214, 9), (173, 12), (212, 18),\n",
        "    (179, 14), (172, 17), (161, 20), (81, 24), (166, 6), (212, 18),\n",
        "    (195, 26), (192, 26)\n",
        "])\n",
        "\n",
        "# Extract x and y values\n",
        "x = points[:, 0]\n",
        "y = points[:, 1]\n",
        "\n",
        "# Calculate necessary sums for the normal equations\n",
        "n = len(x)\n",
        "sum_x = np.sum(x)\n",
        "sum_x2 = np.sum(x**2)\n",
        "sum_x3 = np.sum(x**3)\n",
        "sum_x4 = np.sum(x**4)\n",
        "sum_y = np.sum(y)\n",
        "sum_xy = np.sum(x * y)\n",
        "sum_x2y = np.sum(x**2 * y)\n",
        "\n",
        "# Set up the system of equations\n",
        "A = np.array([\n",
        "    [n, sum_x, sum_x2],\n",
        "    [sum_x, sum_x2, sum_x3],\n",
        "    [sum_x2, sum_x3, sum_x4]\n",
        "])\n",
        "B = np.array([sum_y, sum_xy, sum_x2y])\n",
        "\n",
        "# Solve the system of equations\n",
        "coefficients = np.linalg.solve(A, B)\n",
        "a, b, c = coefficients\n",
        "\n",
        "print(a)\n",
        "print(b)\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBb_RYbF0t-w",
        "outputId": "ae69f9eb-75bf-4f59-c63a-ac0240ab0d48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42.517974985029554\n",
            "-0.30891936050075813\n",
            "0.0009017221798625724\n"
          ]
        }
      ]
    }
  ]
}